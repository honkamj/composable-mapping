{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -11), (0, -11), (0, -11)]\n",
      "[tensor([1.]), tensor([1.]), tensor([1.])]\n",
      "tensor([[ 1.9768,  0.8790,  0.4095,  2.0108, -0.8797],\n",
      "        [ 1.7850,  0.0890,  1.2031, -0.8355, -0.8218],\n",
      "        [-1.0326, -0.8467, -0.5697,  0.3434,  0.4706],\n",
      "        [ 0.7503, -1.1749, -0.8391,  0.5067,  0.7121]])\n",
      "tensor([[ 1.7850,  0.0890, -0.8355, -0.8218, -0.8218],\n",
      "        [-1.0326, -0.8467,  0.3434,  0.4706,  0.4706],\n",
      "        [-1.0326, -0.8467,  0.3434,  0.4706,  0.4706],\n",
      "        [-0.1115, -0.5640, -1.8770, -1.8803, -1.8803]])\n"
     ]
    }
   ],
   "source": [
    "from torch import allclose, float32, device as torch_device, ones, randn, tensor\n",
    "from composable_mapping.affine import Affine\n",
    "from composable_mapping.coordinate_system import CoordinateSystem\n",
    "from composable_mapping.interpolator import LinearInterpolator, NearestInterpolator\n",
    "from composable_mapping.mappable_tensor.affine_transformation import HostAffineTransformation\n",
    "from composable_mapping.mappable_tensor.mappable_tensor import PlainTensor, VoxelGrid\n",
    "from composable_mapping.util import get_spatial_shape\n",
    "\n",
    "grid = (\n",
    "    CoordinateSystem.voxel(\n",
    "        spatial_shape=(3, 4, 5),\n",
    "        dtype=float32,\n",
    "        device=torch_device(\"cpu\"),\n",
    "    )\n",
    "    .shift_voxel(0.5)\n",
    "    .grid()\n",
    ")\n",
    "mask = ones((2, 1, 14, 15, 16), dtype=float32, device=torch_device(\"cpu\"))\n",
    "mask[:, :, :4] = 0.0\n",
    "test_volume = PlainTensor(\n",
    "    randn((2, 3, 14, 15, 16), dtype=float32, device=torch_device(\"cpu\")), mask=mask\n",
    ")\n",
    "interpolator = NearestInterpolator(extrapolation_mode=\"zeros\")\n",
    "# print(test_volume.generate_values()[0, 0, 0])\n",
    "print(interpolator(test_volume, grid).generate_values()[0, 0, 0])\n",
    "print(interpolator(test_volume, grid.reduce()).generate_values()[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Padding value causes wrapping around more than once.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcircular\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hdd/honkamj2/.conda_envs/composable-mapping/lib/python3.8/site-packages/torch/nn/functional.py:4552\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4545\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   4546\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   4547\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4548\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4549\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_replication_pad(\n\u001b[1;32m   4550\u001b[0m                 \u001b[38;5;28minput\u001b[39m, pad\n\u001b[1;32m   4551\u001b[0m             )\n\u001b[0;32m-> 4552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Padding value causes wrapping around more than once."
     ]
    }
   ],
   "source": [
    "torch.nn.functional.pad(\n",
    "    torch.zeros((1, 1, 5, 5, 5)), pad=(20, 20, 20, 20, 20, 20), mode=\"circular\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.pad(torch.zeros(1, 1, 1, 1, dtype=torch.bool), (1, 1, 1, 1), 'constant', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from torch import Tensor\n",
    "from numpy import ndindex\n",
    "\n",
    "from composable_mapping.util import optional_add\n",
    "\n",
    "\n",
    "def _zero_to_none(integer: int) -> Optional[int]:\n",
    "    return integer if integer != 0 else None\n",
    "\n",
    "\n",
    "def _build_slices(kernel_size: int) -> Tuple[slice, ...]:\n",
    "    return tuple(\n",
    "        slice(_zero_to_none(shift), _zero_to_none(shift - kernel_size + 1))\n",
    "        for shift in range(kernel_size)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_nd_slicing(volume: Tensor, kernel: Tensor) -> Tensor:\n",
    "    slices = [_build_slices(kernel_size) for kernel_size in kernel.shape]\n",
    "    output = None\n",
    "    for index in ndindex(*kernel.shape):\n",
    "        slice_tuple = tuple(slice_[i] for slice_, i in zip(slices, index))\n",
    "        output = optional_add(output, volume[(...,) + slice_tuple] * kernel[index])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_volume = torch.randn(1, 1, 128, 128, 128, device=\"cuda:0\").requires_grad_(True)\n",
    "conv_kernel = torch.randn(1, 1, 1, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 255, 255, 255])\n",
      "1123.42431640625\n",
      "0.8255114555358887\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "from composable_mapping.util import optional_add\n",
    "\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "start.record()\n",
    "for _ in range(100):\n",
    "    output_1 = conv_nd_slicing(test_volume, conv_kernel)\n",
    "    output_1.sum().backward()\n",
    "end.record()\n",
    "print(output_1.shape)\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "print(torch.cuda.max_memory_allocated(device=\"cuda:0\") / 1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128, 128])\n",
      "36.58659362792969\n",
      "0.6931252479553223\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats(device=\"cuda:0\")\n",
    "start.record()\n",
    "for _ in range(100):\n",
    "    output_2 = torch.nn.functional.conv3d(test_volume.view(-1, 1, *test_volume.shape[2:]), conv_kernel[None, None])\n",
    "    output_2 = output_2.view(*test_volume.shape[:2] + output_2.shape[2:])\n",
    "    output_2.sum().backward()\n",
    "end.record()\n",
    "print(output_2.shape)\n",
    "torch.cuda.synchronize()\n",
    "print(start.elapsed_time(end))\n",
    "print(torch.cuda.max_memory_allocated(device=\"cuda:0\") / 1024 ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 16324683 / 16581375 (98.5%)\nGreatest absolute difference: 0.005977630615234375 at index (0, 0, 86, 175, 143) (up to 1e-05 allowed)\nGreatest relative difference: 2948.333251953125 at index (0, 0, 59, 125, 245) (up to 1.3e-06 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hdd/honkamj2/.conda_envs/composable-mapping/lib/python3.8/site-packages/torch/testing/_comparison.py:1524\u001b[0m, in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1502\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[1;32m   1503\u001b[0m     actual,\n\u001b[1;32m   1504\u001b[0m     expected,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m   1520\u001b[0m )\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[0;32m-> 1524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 16324683 / 16581375 (98.5%)\nGreatest absolute difference: 0.005977630615234375 at index (0, 0, 86, 175, 143) (up to 1e-05 allowed)\nGreatest relative difference: 2948.333251953125 at index (0, 0, 59, 125, 245) (up to 1.3e-06 allowed)"
     ]
    }
   ],
   "source": [
    "torch.testing.assert_close(output_1, output_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "composable-mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
